RDD
---------
분산되어 존재하는 데이터 요소들의 모임

스파크의 모든 동작은 
 - 새로운 RDD를 만들기
 - 존재하는 RDD변경
 - 결과 계산을 위해 RDD에서 연산을 호출
중에 하나로 표현 

내부에서는 파이크가 자동으로 RDD에 있는 데이터들을 클러스터에 분배하며 클러스터 위에서 수행하는 연산들을 병렬화

RDD 기초
---------
분산되어 있는 변경 불가능한 객체들의 모음

각 RDD는 클러스터의 서로 다른 노드들에서 연산 가능하도록 여러 개의 파티션으로 나뉜다. 
RDD는 사용자가 정의한 클래스를 포함한 파이썬, 자바, 스칼라의 어떤 타입의 객체든 가질 수 있다. 

RDD 만드는 방법
- 외부 데이터 세트를 로드하는 방법
- 드라이버 프로그램에서 객체 컬랙션(list나 set)을 분산시키는 방법

만들어진 RDD는 두가지 타입의 연산을 지원 action과 transformation 임 
- transformation은 존재하는 RDD에서 새로운 RDD를 만듬
    - val pythonLines = lines.filter(line => line.conttains("Python"))  <"Python"을 포함하는 모든 라인을 lines에서 뽑아서 pythonLines로 만듬>

- action은 RDD를 기초로 결과 값을 계산하여 그 값을 드라이버 프로그램에 되돌려 주거나 외부 스토리지에 저장(예: HDFS)
    - pythonLines.first()

lazy evaluation
----
RDD가 생성되는 시점은 처음 액션을 사용하는 시점으로 액션이 실행되기 전에는 선언만 해놓는다. 

그 이유는 입력하자마자 파일의 모든 라인을 로드해서 저장해 놓았더라면 상당한 스토리지 공간의 낭비가 발생

당장에 수많은 라인을 필터링해야 할 처지가 됨

대신에 스파크가 한번에 ㅁ도느 트랜스포메이션끼리의 연계를 파악한다면 결과 도출에 필요한 데이터만을 연산하는 것이 가능하다. 
- 예: first()엑션에서도 처음에 일치하는 라인까지만 읽을 뿐 이후는 읽지 않음

스파크의 RDD들은 기본적으로 액션이 실행될 때마다 매번 새로 연산을 한다. 만약 여러 액션에서 RDD하나를 재사용하고 싶으면 스파크에게 RDD.persist()를 사용하여

계속 결과를 유지하도록 요청할 수 있다. 또한 (메모리, 디스크)에 데이터를 보관해 주도록 스파크에 요청 가능

첫 연산이 이루어진 후 스파크는 RDD의 내용을 메모리에 저장하게 됨(클러스터의 여러 머신에 나눠서) 이후의 액션들에서 재사용한다. 메모리 대신 디스크에 RDD를 저장하는 것도 가능하다. 

데이터를 계산만 하고 저장을 하지 않는 경우도 있다. (일회성 데이터) --> 굳이 스토리지 낭비할 이유가 없어서

현재 31페이지 까지


